
# ğŸŒ Chapter 3 in the Real World

## Designing Data Architecture at Uber Scale

*(Conceptual example inspired by Uber data architecture patterns)*

---

## The Business Problem (Start Here)

Uber needs to answer questions like:

* How many rides happened per city per hour?
* What was average ETA last night?
* Did surge pricing behave correctly?
* Can we retrain ML models daily?

This must work for:

* **Millions of rides/day**
* **Thousands of microservices**
* **Hundreds of data consumers**
* **Near-zero tolerance for wrong numbers**

This is where Chapter 3 principles stop being theory.

---

# 1ï¸âƒ£ Data Generation â€” Where Things Can Go Wrong Fast

### What Uber Generates

Each ride generates events:

* ride_requested
* driver_assigned
* ride_started
* ride_completed
* payment_processed

Each event comes from **different services**.

### âŒ Bad Architecture Choice

Dashboards read directly from live service databases.

```
Ride DB â†’ Dashboard
```

### What Breaks

* Schema change â†’ dashboards break
* Production DB load increases
* Analytics queries slow down the app

> **Real-world outcome:**
> Engineers get paged because dashboards caused app latency.

---

### âœ… Good Architecture (Chapter 3 Thinking)

```
Services â†’ Raw Events â†’ Curated Tables â†’ Consumers
```

* Services emit events
* Data team owns downstream logic
* Production systems are isolated

ğŸ“Œ **Chapter 3 principle:** Loose coupling
ğŸ“Œ **Why it matters at Uber:** App reliability > analytics convenience

---

# 2ï¸âƒ£ Loose Coupling â€” Preventing Cascading Failures

### âŒ Tightly Coupled Uber Example

```
Pricing Service â†’ Spark Job â†’ Surge Dashboard
```

If Pricing changes:

* Spark fails
* Dashboard breaks
* Execs panic

---

### âœ… Loosely Coupled Uber Architecture

```
Pricing Events
   â†“
Raw Pricing Table
   â†“
Curated Surge Metrics
   â†“
Dashboards / ML
```

Now:

* Pricing team can change schemas
* Data team adapts downstream
* Dashboards donâ€™t instantly break

ğŸ“Œ **Chapter 3 core idea:**

> Design so teams can move independently.

---

# 3ï¸âƒ£ Separation of Concerns â€” Who Owns What?

### âŒ Bad Real-World Pattern

One massive pipeline does everything:

* Ingests data
* Cleans data
* Calculates metrics
* Feeds ML
* Powers dashboards

### Why This Fails at Uber Scale

* Nobody knows where bugs live
* One failure kills everything
* Ownership is unclear

---

### âœ… Uber-Style Separation

| Layer          | Responsibility           |
| -------------- | ------------------------ |
| Services       | Emit events              |
| Ingestion      | Collect & store raw data |
| Transformation | Apply business logic     |
| Serving        | Optimize for consumers   |

ğŸ“Œ **Chapter 3 insight:**

> Clear boundaries = faster debugging + accountability.

---

# 4ï¸âƒ£ Single Source of Truth â€” The â€œRevenueâ€ Problem

### Real Problem at Uber

Different teams calculate:

* Gross bookings
* Net revenue
* Driver earnings

Each slightly differently.

### âŒ Without SSOT

* Finance dashboard â‰  Ops dashboard
* Exec meetings turn into debates
* Nobody trusts numbers

---

### âœ… Chapter 3 Solution

* One canonical â€œrides_factâ€ table
* One definition of metrics
* Many downstream uses

```
Canonical Metrics Table
     â†“
Dashboards | ML | Reports
```

ğŸ“Œ **SSOT is not about control â€” itâ€™s about trust.**

---

# 5ï¸âƒ£ Design for Change â€” Surge Logic Changes

### What Changes Often at Uber

* Surge pricing rules
* ETA algorithms
* Incentive calculations

### âŒ Bad Architecture

Overwrite data every day.

Result:

* Canâ€™t recompute past metrics
* Canâ€™t audit decisions
* Canâ€™t explain anomalies

---

### âœ… Good Architecture

* Keep raw immutable data
* Transform via reproducible logic
* Backfill when rules change

ğŸ“Œ **Chapter 3 truth:**

> History is priceless. Never throw raw data away.

---

# 6ï¸âƒ£ Design for Failure â€” Late & Missing Data

### Real Uber Scenario

* Some driver phones go offline
* Events arrive late
* Network hiccups happen

### âŒ Bad Architecture

Assumes data arrives on time.

Result:

* Wrong dashboards
* Broken ML features
* Silent errors

---

### âœ… Uber-Scale Design

* Accept late data
* Allow reprocessing
* Monitor freshness

ğŸ“Œ **Failure is normal at scale. Silence is not.**

---

# 7ï¸âƒ£ Cost-Aware Architecture â€” Why Streaming Everything Hurts

### Temptation

Uber could stream *everything* in real time.

### Reality

* Streaming infra is expensive
* Most analytics donâ€™t need second-level latency

### Smart Choice

* Batch for analytics
* Streaming only for critical systems (ETA, fraud)

ğŸ“Œ **Chapter 3 lesson:**

> Real-time is a business decision, not a flex.

---

# 8ï¸âƒ£ Architecture Is Socio-Technical (People Matter)

### Uber Has:

* Hundreds of engineers
* Dozens of teams
* Constant onboarding

### âŒ Over-Engineered Architecture

* Only original designers understand it
* New hires break things
* Bus factor = 1

---

### âœ… Good Architecture

* Predictable layers
* Documented patterns
* Easy mental model

ğŸ“Œ **If people canâ€™t reason about the system, it will fail.**

---

# ğŸ§  How Meta Is Similar (Quick Contrast)

At **Meta**:

* Data volume is even larger
* Batch dominates analytics
* Strong emphasis on:

  * Canonical datasets
  * Reproducibility
  * Internal data products

Same Chapter 3 principles, different scale.

---

# ğŸš¨ What Happens If Uber Ignores Chapter 3

| Ignored Principle | Outcome                |
| ----------------- | ---------------------- |
| Loose coupling    | Cascading outages      |
| SSOT              | Exec distrust          |
| Separation        | Debugging hell         |
| Failure design    | Silent data corruption |
| Cost awareness    | Massive cloud bills    |

---

# ğŸ§  Final Real-World Mental Model

```
Uber-scale data architecture exists to:
- Protect production systems
- Let teams move independently
- Preserve history
- Maintain trust in numbers
- Keep costs predictable
```

---

## One-Sentence Chapter 3 (Real-World Version)

> **At companies like Uber, good data architecture is what allows thousands of engineers to ship changes without breaking analytics, ML, or trust.**


## ğŸ§± Uber-style Snowflake + Spark + Airflow architecture diagram

Hereâ€™s a **full, realistic** (but still readable) â€œUber-ishâ€ stack showing **layers, ownership boundaries, and failure containment**.

```text
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                 SOURCE SYSTEMS                    â”‚
                â”‚  Ride svc | Driver svc | Pricing svc | Payments   â”‚
                â”‚  ETA svc  | Fraud svc  | Support svc | Mobile app â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚  (events / CDC / APIs)
                                v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INGESTION & LANDING                             â”‚
â”‚                                                                         â”‚
â”‚  Airflow DAGs (or event triggers)                                        â”‚
â”‚  - extract_cdc_*   - ingest_events_*   - ingest_apis_*                   â”‚
â”‚  - retries, SLAs, alerts, backfills                                      â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                              â”‚
                â”‚ batch/near-real-time         â”‚ streaming (only where needed)
                v                              v
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  Snowflake: RAW    â”‚           â”‚  (optional) Stream bus â”‚
      â”‚  database/schema   â”‚           â”‚  Kafka/Kinesis/PubSub  â”‚
      â”‚  - append-only      â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚  - minimal changes  â”‚                    â”‚
      â”‚  - source-aligned   â”‚                    v
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚                      â”‚ Snowflake: RAW (streamsâ”‚
                 â”‚                      â”‚ land here too)         â”‚
                 v                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROCESSING / TRANSFORMATION (SPARK)                   â”‚
â”‚                                                                         â”‚
â”‚  Spark jobs (Databricks/EMR/etc.)                                        â”‚
â”‚  - clean + standardize (timestamps, ids, schemas)                        â”‚
â”‚  - dedupe + late-event handling                                          â”‚
â”‚  - build conformed dimensions (city, product, rider, driver)             â”‚
â”‚  - build facts (rides, trips, payments)                                  â”‚
â”‚                                                                         â”‚
â”‚  Orchestrated by Airflow:                                                â”‚
â”‚  RAW â†’ STAGING â†’ CURATED â†’ MARTS                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                v
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚             Snowflake: CURATED / CORE              â”‚
      â”‚  â€œsingle source of truthâ€ (SSOT) tables            â”‚
      â”‚  - dim_rider, dim_driver, dim_city                 â”‚
      â”‚  - fact_trip, fact_payment, fact_pricing           â”‚
      â”‚  - audited definitions + versioned logic           â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                           â”‚
                 â”‚                           â”‚
                 v                           v
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Snowflake: DATA MARTS     â”‚  â”‚ Snowflake: FEATURE / SERVING      â”‚
   â”‚  - exec dashboards        â”‚  â”‚  - ML feature tables              â”‚
   â”‚  - ops metrics            â”‚  â”‚  - near-real-time aggregates      â”‚
   â”‚  - city-level KPIs        â”‚  â”‚  - reverse ETL exports            â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                               â”‚
               v                               v
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ BI / Analytics        â”‚         â”‚ ML / Product Consumption      â”‚
   â”‚ Looker/Tableau/etc.   â”‚         â”‚ - model training pipelines    â”‚
   â”‚ Ad-hoc SQL users      â”‚         â”‚ - online services via exports â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚               CROSS-CUTTING LAYERS                 â”‚
                 â”‚  Observability: freshness, volume, null-rate, SLA â”‚
                 â”‚  Governance: lineage, catalog, access control      â”‚
                 â”‚  Security/Privacy: PII masking, row-level security â”‚
                 â”‚  Cost: warehouse sizing, job tuning, retention     â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What makes this â€œUber-styleâ€ (the Chapter 3 principles baked in)

* **Loose coupling:** services â†’ raw â†’ curated â†’ marts (no dashboards touching prod DBs)
* **Separation of concerns:** ingestion â‰  transformation â‰  serving
* **SSOT:** curated/core tables are the â€œofficial truthâ€
* **Designed for change:** raw is retained; curated is reproducible; backfills are normal
* **Designed for failure:** retries + alerts + late data handling + data quality checks

---

## ğŸ¯ Interview answers: â€œHow would you design Uberâ€™s data platform?â€

Below are **ready-to-say** answers (you can shorten/expand depending on interviewer).

### 1) â€œWalk me through your architecture.â€

**Answer (structured, 45â€“60 sec):**
â€œIâ€™d design a layered architecture: source services emit events/CDC into a landing layer, then an immutable raw layer in the warehouse. Spark handles heavy transformsâ€”standardization, dedupe, late eventsâ€”into curated conformed dimensions and fact tables that act as the single source of truth. From curated, Iâ€™d publish purpose-built marts for BI and feature/serving tables for ML and operational use cases. Airflow orchestrates dependencies, SLAs, retries, and backfills. Cross-cutting concerns include observability for freshness/volume checks, governance/lineage, and security for PII masking and access control.â€

### 2) â€œHow do you prevent schema changes from breaking everything?â€

**Answer:**
â€œBy **decoupling** producers from consumers. Producers land into a raw layer with minimal transformation and schema evolution handling. Downstream curated models are versioned and validated. If a source changes a field name or type, the blast radius is contained to the staging/transform layer, not dashboards. Iâ€™d also add contract tests and schema checks at ingestion.â€

### 3) â€œHow do you handle late or out-of-order events?â€

**Answer:**
â€œI assume late events are normal at scale. Iâ€™d design the transform layer with event-time semantics, watermarking where relevant, and idempotent upserts keyed by stable identifiers. Iâ€™d support reprocessing windows and periodic backfills, and Iâ€™d monitor lateness distributions so we can tune SLAs and data readiness policies.â€

### 4) â€œWhat is your Single Source of Truth and why?â€

**Answer:**
â€œThe SSOT is the curated/core layerâ€”conformed dims and facts like `fact_trip` and `fact_payment`. Itâ€™s where business definitions live: what counts as a completed trip, how revenue is computed, what cancellations mean. Having one canonical layer prevents metric drift between finance, ops, and ML.â€

### 5) â€œBatch vs streaming: what would you choose for Uber?â€

**Answer:**
â€œBatch by default for analytics and reporting because itâ€™s simpler, cheaper, and more reliable. Streaming only where it creates real business valueâ€”fraud detection, real-time ETA monitoring, incident response. Even then, Iâ€™d still land streaming outputs into the warehouse so history and auditability remain intact.â€

### 6) â€œHow would you ensure data quality?â€

**Answer:**
â€œIâ€™d implement quality checks at multiple points: ingestion (row counts, schema validation), transformation (uniqueness keys, null thresholds, referential integrity), and serving (freshness SLAs). Failures should alert and block downstream publication. Iâ€™d also track quality metrics over time like anomaly detection on volumes and key distributions.â€

### 7) â€œHow do you keep costs under control?â€

**Answer:**
â€œCost is a first-class constraint. Iâ€™d partition/cluster appropriately, use incremental processing instead of full recomputes, right-size Snowflake warehouses, and separate compute for heavy ETL vs BI. Iâ€™d set retention policies for raw where appropriate and monitor query hotspots, caching opportunities, and job inefficiencies.â€

### 8) â€œHow do you support ML feature needs without breaking BI?â€

**Answer:**
â€œIâ€™d keep **feature serving** as its own publishing path off the curated layer. ML often needs point-in-time correctness, backfills, and different granularity than BI. So Iâ€™d create feature tables with strict time travel / snapshot logic and ensure theyâ€™re reproducible, while BI marts stay stable and business-friendly.â€

### 9) â€œWhat would you do in the first 30â€“60 days building this?â€

**Answer:**
â€œStart with the critical path: pick 1â€“2 core domains like trips and payments, build the raw ingestion + curated SSOT + one executive mart. Add observability and alerting early. Document ownership and definitions. Then expand domain-by-domain while enforcing the same layered pattern.â€

### 10) â€œHow do you design this for teams and ownership?â€

**Answer:**
â€œIâ€™d define clear ownership boundaries: service teams own event production, data platform owns ingestion and shared infrastructure, and analytics/data engineering owns curated models and marts. Iâ€™d publish datasets as â€˜data productsâ€™ with SLAs, documentation, and on-call rotation aligned to business criticality.â€

---
Got it â€” you want **plain-English definitions** of these terms, no fluff, no essays.
Think **glossary + intuition**. Letâ€™s do that ğŸ‘‡

---

# ğŸ“˜ Core Data Architecture Terms (Simple Explanations)

---

## ğŸ§± Data Mart (often just called â€œmartâ€)

### What it is

A **data mart** is a **small, purpose-built dataset** designed for a **specific use case**.

### In simple terms

> A mart is data thatâ€™s already shaped exactly how someone needs it.

### Example

At Uber:

* **Exec mart** â†’ daily revenue by city
* **Ops mart** â†’ trips per hour, cancellations
* **Marketing mart** â†’ promo effectiveness

Instead of everyone querying massive raw tables, they query **clean, ready-to-use tables**.

### Why marts exist

* Faster queries
* Easier for non-engineers
* Prevents people from breaking core data

---

## ğŸ”— Loose Coupling

### What it is

Systems are connected **indirectly**, not tightly bound to each other.

### In simple terms

> One thing can change without breaking everything else.

### Bad (tight coupling)

```
Dashboard â†’ Production DB
```

### Good (loose coupling)

```
Service â†’ Raw â†’ Curated â†’ Mart â†’ Dashboard
```

### Why this matters

* Apps change often
* Dashboards should not break when apps change
* Teams can work independently

---

## ğŸ§  Separation of Concerns

### What it is

Each part of the system does **one job only**.

### In simple terms

> Donâ€™t mix responsibilities.

### Example

* Ingestion â†’ just moves data
* Transformation â†’ just applies logic
* Serving â†’ just presents data

### Why it matters

* Easier debugging
* Clear ownership
* Less chaos

---

## ğŸ›ï¸ SSOT (Single Source of Truth)

### What it is

One **authoritative place** where business logic and metrics are defined.

### In simple terms

> One version of the truth â€” everyone agrees on it.

### Example

* One definition of â€œcompleted tripâ€
* One revenue calculation

Without SSOT:

* Dashboards disagree
* Meetings turn into arguments

---

## ğŸ”„ Backfill

### What it is

Re-processing **past data** using new or corrected logic.

### In simple terms

> â€œWe fixed the logic â€” now letâ€™s recompute history.â€

### Example

* Bug found in revenue logic from last month
* Re-run transformations for that month

Backfills are **normal**, not emergencies.

---

## ğŸ§± Raw Data

### What it is

Data exactly as it comes from the source.

### In simple terms

> Untouched, messy, original data.

### Why keep raw data

* You can always reprocess
* You donâ€™t lose history
* You can fix past mistakes

---

## ğŸ§ª Curated Data

### What it is

Cleaned, standardized, business-ready data.

### In simple terms

> Data that humans and systems can trust.

### Example

* Clean timestamps
* Deduplicated records
* Standard definitions

This is usually where **SSOT lives**.

---

## âš ï¸ Designed for Change

### What it means

You **expect**:

* Logic bugs
* Schema changes
* New requirements

So you:

* Keep raw data
* Rebuild curated data
* Backfill when needed

> Change is normal, not failure.

---

## ğŸ’¥ Designed for Failure

### What it means

You assume things **will break**.

So you add:

* Retries
* Alerts
* Data quality checks
* Late data handling

### In simple terms

> Systems should fail loudly and safely.

---

## ğŸ“Š Data Quality Checks

### What they are

Rules to detect bad data.

### Examples

* â€œRow count dropped 80%â€
* â€œToo many nullsâ€
* â€œData is lateâ€

Bad data is **blocked**, not silently served.

---

## ğŸ§  One-Screen Mental Model (Memorize This)

```
Raw â†’ Curated â†’ Marts
 |       |         |
Keep   Define    Serve
history truth    users
```

---

## ğŸ”‘ Ultra-Short Definitions (Interview-Ready)

* **Mart**: purpose-built dataset for a specific audience
* **Loose coupling**: changes donâ€™t cascade
* **Separation of concerns**: one layer, one job
* **SSOT**: one authoritative definition of metrics
* **Backfill**: recompute historical data
* **Raw data**: immutable source data
* **Curated data**: clean, trusted data
* **Designed for failure**: expect and handle breaks

---


